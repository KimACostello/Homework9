[
  {
    "objectID": "HW9_Costello.html",
    "href": "HW9_Costello.html",
    "title": "Homework 9: Modeling Practice",
    "section": "",
    "text": "Seoul Bike Sharing Demand Dataset\n\nlibrary(readr)\nlibrary(broom)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ dials        1.4.2     ✔ tailor       0.1.0\n✔ infer        1.0.9     ✔ tidyr        1.3.1\n✔ modeldata    1.5.1     ✔ tune         2.0.1\n✔ parsnip      1.3.3     ✔ workflows    1.3.0\n✔ purrr        1.1.0     ✔ workflowsets 1.1.1\n✔ recipes      1.3.1     ✔ yardstick    1.3.2\n✔ rsample      1.3.1     \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n\nThe following data set is provided by the UCI Machine Learning Repository. The data set contains count of public bicycles rented per hours in the Seoul Bike Sharing System, with corresponding weather data and holiday information.\nThe following variables are provided:\n\nDate - day/month/year\nRented Bike count - Count of bikes rented at each hour\nHour - Hour of the day\nTemperature-Temperature in Celsius\nHumidity - %\nWindspeed - m/s\nVisibility - 10m\nDew point temperature - Celsius\nSolar radiation - MJ/m2\nRainfall - mm\nSnowfall - cm\nSeasons - Winter, Spring, Summer, Autumn\nHoliday - Holiday/No holiday\nFunctional Day - NoFunc(Non Functional Hours), Fun(Functional hours)\n\n\n# Read in data\nbike_data &lt;- read_csv(\"SeoulBikeData.csv\", locale = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nEDA\nBefore we summarize the data, let’s determine if the data set contains any missing values.\n\n# check for missing values\ncolSums(is.na(bike_data))\n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\nThe data provided does not contain any missing values.\nThe following contains the structure of the data set, so we can see the different variables and how they are being stored.\n\nstr(bike_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nBelow is a summary of basic stats that can be used to make sure the data makes sense.\n\nsummary(bike_data)\n\n     Date           Rented Bike Count      Hour       Temperature(°C) \n Length:8760        Min.   :   0.0    Min.   : 0.00   Min.   :-17.80  \n Class :character   1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50  \n Mode  :character   Median : 504.5    Median :11.50   Median : 13.70  \n                    Mean   : 704.6    Mean   :11.50   Mean   : 12.88  \n                    3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50  \n                    Max.   :3556.0    Max.   :23.00   Max.   : 39.40  \n  Humidity(%)    Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   : 0.00   Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:42.00   1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :57.00   Median :1.500    Median :1698     Median :  5.100          \n Mean   :58.23   Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:74.00   3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :98.00   Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)       Seasons         \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000   Length:8760       \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000   Class :character  \n Median :0.0100          Median : 0.0000   Median :0.00000   Mode  :character  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507                     \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000                     \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000                     \n   Holiday          Functioning Day   \n Length:8760        Length:8760       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\n\nunique(bike_data$Seasons)\n\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\nunique(bike_data$Holiday)\n\n[1] \"No Holiday\" \"Holiday\"   \n\nunique(bike_data$`Functioning Day`)\n\n[1] \"Yes\" \"No\" \n\n\nUnique values for Seasons are Winter, Spring, Summer, and Autumn. The holiday variable value for an observation is either No Holiday or Holiday. The Functioning Day is either Yes or No (Yes, it is during functional hours or No, it is not).\nLet’s manipulate the data by:\n\nconverting the date column to an actual date.\nturning the character variables into factors (for the different levels/categories).\nrenaming all the variables to snake case.\n\n\nbike_data &lt;- bike_data |&gt;\n  mutate(\n     Date = dmy(Date),\n     Seasons = as.factor(Seasons),\n     Holiday = as.factor(Holiday),\n     `Functioning Day` = as.factor(`Functioning Day`)\n  ) |&gt;\n  clean_names(\"snake\")\n\nLet’s see how many observations occurred in each season during functional or non-functional hours. And let’s see how many observations occurred during a holiday vs no holiday during functional and non-functional hours.\n\n# Two-way contingency tables\ntable(bike_data$functioning_day, bike_data$seasons)\n\n     \n      Autumn Spring Summer Winter\n  No     247     48      0      0\n  Yes   1937   2160   2208   2160\n\ntable(bike_data$functioning_day, bike_data$holiday)\n\n     \n      Holiday No Holiday\n  No       24        271\n  Yes     408       8057\n\n\nThere are no observations in Summer and Winter that occurred during non-functional hours. Most observations are not on a holiday and during functional hours.\nLet’s look at the Mean and Median for all numeric variables during functional and non-functional hours.\n\nbike_data |&gt;\n  group_by(functioning_day) |&gt;\n  summarize(across(where(is.numeric), \n                   list(\"mean\" = mean, \"median\" = median), \n                   .names = \"{.fn}_{.col}\"))\n\n# A tibble: 2 × 21\n  functioning_day mean_rented_bike_count median_rented_bike_count mean_hour\n  &lt;fct&gt;                            &lt;dbl&gt;                    &lt;dbl&gt;     &lt;dbl&gt;\n1 No                                  0                         0      11.3\n2 Yes                               729.                      542      11.5\n# ℹ 17 more variables: median_hour &lt;dbl&gt;, mean_temperature_c &lt;dbl&gt;,\n#   median_temperature_c &lt;dbl&gt;, mean_humidity_percent &lt;dbl&gt;,\n#   median_humidity_percent &lt;dbl&gt;, mean_wind_speed_m_s &lt;dbl&gt;,\n#   median_wind_speed_m_s &lt;dbl&gt;, mean_visibility_10m &lt;dbl&gt;,\n#   median_visibility_10m &lt;dbl&gt;, mean_dew_point_temperature_c &lt;dbl&gt;,\n#   median_dew_point_temperature_c &lt;dbl&gt;, mean_solar_radiation_mj_m2 &lt;dbl&gt;,\n#   median_solar_radiation_mj_m2 &lt;dbl&gt;, mean_rainfall_mm &lt;dbl&gt;, …\n\n\nThe mean and median rented bike counts are zero during non-functional hours.\nTo confirm there are no bikes being rented during non-functional hours, let’s look at the min and max rental bike counts.\n\nbike_data |&gt;\n  group_by(functioning_day) |&gt;\n  summarize(min_bike_count = min(rented_bike_count), max_bike_count = max(rented_bike_count))\n\n# A tibble: 2 × 3\n  functioning_day min_bike_count max_bike_count\n  &lt;fct&gt;                    &lt;dbl&gt;          &lt;dbl&gt;\n1 No                           0              0\n2 Yes                          2           3556\n\n\nNo bikes were rented during non-functional hours.\nSince no bikes are being rented during non-functional hours, we can remove the observations that occurred during non-functional hours.\n\nfun_bike_data &lt;- bike_data |&gt;\n  filter(functioning_day == \"Yes\")\n\nTo simplify analysis, let’s summarize across the hours so each day has one observation with it. This can be done by grouping by character variables, and summarizing (either sum or mean) across numeric variables.\n\nbike_summary_data &lt;- fun_bike_data |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarize(\n    sum_bike_count = sum(rented_bike_count),\n    sum_rainfall = sum(rainfall_mm),\n    sum_snowfall = sum(snowfall_cm),\n    across(c(temperature_c, \n             humidity_percent,\n             wind_speed_m_s,\n             visibility_10m,\n             dew_point_temperature_c,\n             solar_radiation_mj_m2), \n           ~ mean(.x),\n           .names = \"mean_{.col}\")\n    \n  )\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\nhead(bike_summary_data)\n\n# A tibble: 6 × 12\n# Groups:   date, seasons [6]\n  date       seasons holiday    sum_bike_count sum_rainfall sum_snowfall\n  &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;               &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 2017-12-01 Winter  No Holiday           9539          0            0  \n2 2017-12-02 Winter  No Holiday           8523          0            0  \n3 2017-12-03 Winter  No Holiday           7222          4            0  \n4 2017-12-04 Winter  No Holiday           8729          0.1          0  \n5 2017-12-05 Winter  No Holiday           8307          0            0  \n6 2017-12-06 Winter  No Holiday           6669          1.3          8.6\n# ℹ 6 more variables: mean_temperature_c &lt;dbl&gt;, mean_humidity_percent &lt;dbl&gt;,\n#   mean_wind_speed_m_s &lt;dbl&gt;, mean_visibility_10m &lt;dbl&gt;,\n#   mean_dew_point_temperature_c &lt;dbl&gt;, mean_solar_radiation_mj_m2 &lt;dbl&gt;\n\n\nNow that non-functional hours have been removed from the data, let’s see the number of observations that occurred on a holiday or no holiday by the season.\n\ntable(bike_summary_data$seasons, bike_summary_data$holiday)\n\n        \n         Holiday No Holiday\n  Autumn       4         77\n  Spring       3         87\n  Summer       2         90\n  Winter       8         82\n\n\nLet’s get the mean and median of numeric variables without the non-functional hours observations, by seasons.\n\nbike_summary_data |&gt;\n  group_by(seasons) |&gt;\n  summarize(across(where(is.numeric), \n                   list(\"mean\" = mean, \"median\" = median), \n                   .names = \"{.fn}_{.col}\"))\n\n# A tibble: 4 × 19\n  seasons mean_sum_bike_count median_sum_bike_count mean_sum_rainfall\n  &lt;fct&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;             &lt;dbl&gt;\n1 Autumn               22099.                23350              2.81 \n2 Spring               17910.                17590              4.49 \n3 Summer               24818.                25572.             6.08 \n4 Winter                5413.                 5498              0.788\n# ℹ 15 more variables: median_sum_rainfall &lt;dbl&gt;, mean_sum_snowfall &lt;dbl&gt;,\n#   median_sum_snowfall &lt;dbl&gt;, mean_mean_temperature_c &lt;dbl&gt;,\n#   median_mean_temperature_c &lt;dbl&gt;, mean_mean_humidity_percent &lt;dbl&gt;,\n#   median_mean_humidity_percent &lt;dbl&gt;, mean_mean_wind_speed_m_s &lt;dbl&gt;,\n#   median_mean_wind_speed_m_s &lt;dbl&gt;, mean_mean_visibility_10m &lt;dbl&gt;,\n#   median_mean_visibility_10m &lt;dbl&gt;, mean_mean_dew_point_temperature_c &lt;dbl&gt;,\n#   median_mean_dew_point_temperature_c &lt;dbl&gt;, …\n\n\nNot surprisingly, the most bike rentals occurred during the Summer, then Autumn.\nLet’s see the min and max daily bike rentals by season.\n\nbike_summary_data |&gt;\n  group_by(seasons) |&gt;\n  summarize(min_bike_count = min(sum_bike_count), max_bike_count = max(sum_bike_count))\n\n# A tibble: 4 × 3\n  seasons min_bike_count max_bike_count\n  &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Autumn            1721          31809\n2 Spring             977          31681\n3 Summer            3231          36149\n4 Winter            2014           9539\n\n\nLet’s generate a correlation matrix plot, so we can see the relationships between the numeric variables.\n\ndf_corr &lt;- bike_summary_data |&gt;\n  select(where(is.numeric)) |&gt;\n  rename(\"Bike_count\" = sum_bike_count,\n         \"Rainfall\" = sum_rainfall,\n         \"Snowfall\" = sum_snowfall,\n         \"Temperature\" = mean_temperature_c,\n         \"Humidity\" = mean_humidity_percent,\n         \"Windspeed\" = mean_wind_speed_m_s,\n         \"Visibility\" = mean_visibility_10m,\n         \"Dew_point\" = mean_dew_point_temperature_c,\n         \"Solar_radiation\" = mean_solar_radiation_mj_m2)\n\nAdding missing grouping variables: `date`, `seasons`\n\nggcorr(df_corr, \n       nbreaks = 6,\n       label = TRUE,\n       palette = \"BuPu\",\n       size = 2,          # adjusting variable names sizes\n       hjust = 0.65) +    # adjusting position of variable names) \n  labs(title = \"Correlation Matrix of all Numeric Variables\") +\n  ggeasy::easy_center_title()\n\nWarning: data in columns date and seasons are not numeric and were ignored\n\n\n\n\n\n\n\n\n\nWhen looking at daily bike rentals, temperature has the greatest positive correlation (the higher the temp, the higher the # of bike rentals). Humidity does not appear to have any relationship with bike rental counts.\n\ndf_corr |&gt;\n  group_by(seasons) |&gt;\n  summarize(correlation = cor(Bike_count, Temperature, use = \"pairwise.complete.obs\"))\n\n# A tibble: 4 × 2\n  seasons correlation\n  &lt;fct&gt;         &lt;dbl&gt;\n1 Autumn        0.538\n2 Spring        0.654\n3 Summer       -0.217\n4 Winter        0.471\n\n\nWhen looking at the relationship between bike counts and temperature across seasons, it’s surprising to see that summer has a slight negative correlation. Spring has a greater positive correlation between temperature and bike counts.\nLet’s see some plots to explore the data.\nScatterplot:\n\ng &lt;- ggplot(data = bike_summary_data)\n\ng + geom_point(aes(x = sum_bike_count, \n                   y = sum_rainfall, \n                   color = seasons)) +\n  labs(x = \"Rental Bike Count\", \n       y = \"Rainfall (mm)\",\n       title = \"Rental Bike Count by Total Daily Rainfall\",\n       color = \"Seasons\") +\n  scale_color_manual(values = c(\"#FFFF00\",\n                                \"#FF00FF\",\n                                \"#7FFF00\",\n                                \"#00FFFF\")) +\n  theme_dark() +\n  ggeasy::easy_center_title() \n\n\n\n\n\n\n\n\nIn the plot above, you can see rental bike counts vs rainfall. The points are also color coded by season. Bike rentals are greater in the summer, but there are fewer observations during heavy rainfall.\nBoxplot:\n\ng + geom_boxplot(aes(x = seasons, y = sum_bike_count, fill = holiday)) +\n  labs(x = \"Seasons\", \n       y = \"Daily Rental Bike Count\",\n       title = \"Daily Rental Bike Count by Seasons\",\n       fill = \"Holiday\") +\n  ggeasy::easy_center_title() +\n  scale_fill_manual(values = c(\"lightpink\",\n                               \"lightblue\"))\n\n\n\n\n\n\n\n\nIn the plot above, you can see that bike rental counts are greater in Summer and Autumn. Spring has a larger range of bike counts on a given day (greater distance between the min and max).\nScatterplot with a regression line:\n\nggplot(bike_summary_data, aes(x = date, y = sum_bike_count)) +\n  geom_point() +\n  labs(x = \"Date\", \n       y = \"Daily Rental Bike Count\",\n       title = \"Daily Rental Bike Count by Date\") +\n  ggeasy::easy_center_title() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIn the plot above, you can see the trend of daily bike rentals by date, throughout 2018. Between June and July appear to have the most daily bike rentals, and January has the lowest.\n\n\nSplitting the Data\nSplit the data into training and test set.\n\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \nset.seed(123)\n# Put 3/4 of the data into the training set \ndata_split &lt;- initial_split(bike_summary_data, prop = 3/4, strata = seasons)\n\n# Create data frames for the two sets:\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n# Create 10-fold cross validation split on the training data\nbike_folds &lt;- vfold_cv(train_data, 10)\n\n\n\nFitting MLR Models\nLet’s create some recipes.\n\nrecipe_one &lt;- recipe(sum_bike_count ~ ., data = train_data) |&gt; \n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(day_of_week = \n                as.factor(ifelse(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  step_rm(date_dow) |&gt;     #removes intermediate variable\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, day_of_week)\n\n\n# Same as recipe one except including interactions.\nrecipe_two &lt;- recipe(sum_bike_count ~ ., data = train_data) |&gt; \n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(day_of_week = \n                as.factor(ifelse(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  step_rm(date_dow) |&gt;     #removes intermediate variable\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, day_of_week) |&gt;\n  step_interact(terms = ~starts_with(\"holiday\")*starts_with(\"seasons\") +\n                  ~mean_temperature_c*starts_with(\"seasons\") +\n                  ~mean_temperature_c*sum_rainfall)\n\n\n# Same as recipe two except adding quadratic terms to numeric predictors.\nrecipe_three &lt;- recipe(sum_bike_count ~ ., data = train_data) |&gt; \n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(day_of_week = \n                as.factor(ifelse(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))) |&gt;\n  step_rm(date_dow) |&gt;     #removes intermediate variable\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, day_of_week) |&gt;\n  step_interact(terms = ~starts_with(\"holiday\")*starts_with(\"seasons\") +\n                  ~mean_temperature_c*starts_with(\"seasons\") +\n                  ~mean_temperature_c*sum_rainfall) |&gt;\n  step_poly(starts_with(\"mean\"), sum_rainfall, sum_snowfall)\n\nNow, let’s set up our linear model fit to use the lm engine.\n\nMLR_spec &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\nCombining recipes and model into workflows (for each recipe).\n\nworkflow_one &lt;- workflow() |&gt;\n  add_recipe(recipe_one) |&gt;\n  add_model(MLR_spec)\n\nworkflow_two &lt;- workflow() |&gt;\n  add_recipe(recipe_two) |&gt;\n  add_model(MLR_spec)\n\nworkflow_three &lt;- workflow() |&gt;\n  add_recipe(recipe_three) |&gt;\n  add_model(MLR_spec)\n\nFit the models using the 10 fold CV.\n\nbike_CV_fit_one &lt;- workflow_one |&gt;\n  fit_resamples(bike_folds)\nbike_CV_fit_one\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n\nbike_CV_fit_one |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n   std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   4178.       10 144.      pre0_mod0_post0\n2 rsq     standard      0.827    10   0.00853 pre0_mod0_post0\n\n\n\nbike_CV_fit_two &lt;- workflow_two |&gt;\n  fit_resamples(bike_folds)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nbike_CV_fit_two\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [1 × 4]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from rank-deficient fit; consider predict(., rankdefic...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\nbike_CV_fit_two |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   2990.       10 232.     pre0_mod0_post0\n2 rsq     standard      0.906    10   0.0148 pre0_mod0_post0\n\n\n\nbike_CV_fit_three &lt;- workflow_three |&gt;\n  fit_resamples(bike_folds)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nbike_CV_fit_three\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [1 × 4]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 4]&gt;\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from rank-deficient fit; consider predict(., rankdefic...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\nbike_CV_fit_three |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   2939.       10 236.     pre0_mod0_post0\n2 rsq     standard      0.908    10   0.0152 pre0_mod0_post0\n\n\nModel 3 is the best fit (lowest RMSE and highest RSQ).\nUsing the “best” model, fit the model to the entire training data set.\n\nbest_fit &lt;- \n  workflow_three |&gt;\n  last_fit(data_split)\n\nbest_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    2950.    pre0_mod0_post0\n2 rsq     standard       0.917 pre0_mod0_post0\n\n\nObtain the final model coefficient table.\n\nbest_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 30 × 5\n   term                                estimate std.error statistic  p.value\n   &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                           15127.     2181.     6.93  3.97e-11\n 2 seasons_Spring                        -7314.     3715.    -1.97  5.02e- 2\n 3 seasons_Summer                        17027.     3515.     4.84  2.33e- 6\n 4 seasons_Winter                        -7739.     3180.    -2.43  1.57e- 2\n 5 holiday_No.Holiday                     6216.     2055.     3.03  2.77e- 3\n 6 day_of_week_weekend                   -2433.      392.    -6.21  2.47e- 9\n 7 holiday_No.Holiday_x_seasons_Spring    2520.     3752.     0.672 5.02e- 1\n 8 holiday_No.Holiday_x_seasons_Summer   -2849.     2881.    -0.989 3.24e- 1\n 9 holiday_No.Holiday_x_seasons_Winter   -3753.     2459.    -1.53  1.28e- 1\n10 seasons_Spring_x_mean_temperature_c    4524.     1115.     4.06  6.80e- 5\n# ℹ 20 more rows\n\n\n\n\n\n\nHomework 9\n\nLASSO model\n\n# set up model\nLASSO_spec &lt;- linear_reg(penalty = tune(), mixture = 1) |&gt;\n  set_engine(\"glmnet\")\n\n#create workflow\nLASSO_wkf &lt;- workflow() |&gt;\n  add_recipe(recipe_one) |&gt;\n  add_model(LASSO_spec)\nLASSO_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n# Fit the model\nLASSO_grid &lt;- LASSO_wkf |&gt;\n  tune_grid(resamples = bike_folds,\n            grid = grid_regular(penalty(), levels = 200)) \n\nLASSO_grid[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config          \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;            \n 1 1   e-10 rmse    standard    3608.    pre0_mod001_post0\n 2 1   e-10 rsq     standard       0.875 pre0_mod001_post0\n 3 1.12e-10 rmse    standard    3608.    pre0_mod002_post0\n 4 1.12e-10 rsq     standard       0.875 pre0_mod002_post0\n 5 1.26e-10 rmse    standard    3608.    pre0_mod003_post0\n 6 1.26e-10 rsq     standard       0.875 pre0_mod003_post0\n 7 1.41e-10 rmse    standard    3608.    pre0_mod004_post0\n 8 1.41e-10 rsq     standard       0.875 pre0_mod004_post0\n 9 1.59e-10 rmse    standard    3608.    pre0_mod005_post0\n10 1.59e-10 rsq     standard       0.875 pre0_mod005_post0\n# ℹ 390 more rows\n\n\n\n# Pull out the best model\nbest_LASSO &lt;- LASSO_grid |&gt;\n  select_best(metric = \"rmse\")\nbest_LASSO\n\n# A tibble: 1 × 2\n       penalty .config          \n         &lt;dbl&gt; &lt;chr&gt;            \n1 0.0000000001 pre0_mod001_post0\n\n\n\n# Fit best LASSO model on the entire training set.\nLASSO_final_fit &lt;- LASSO_wkf |&gt;\n  finalize_workflow(best_LASSO) |&gt;\n  last_fit(data_split, metrics = metric_set(rmse, mae))\n\nLASSO_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       4060. pre0_mod0_post0\n2 mae     standard       3157. pre0_mod0_post0\n\n\n\n\nRegression Tree Model\n\n# Define model and engine\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                            min_n = 20,\n                            cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n# Create Workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(recipe_one) |&gt;\n  add_model(tree_mod)\n\n# Fit the workflow to the CV folds\ntree_fit &lt;- tree_wkf |&gt; \n  tune_grid(resamples = bike_folds)\n\ntree_fit |&gt; \n  collect_metrics()|&gt;\n  filter(.metric == \"rmse\") |&gt;\n  arrange(mean)\n\n# A tibble: 10 × 8\n   cost_complexity tree_depth .metric .estimator  mean     n std_err .config    \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1    0.0001                8 rmse    standard   3693.    10    228. pre0_mod07…\n 2    0.0000001             7 rmse    standard   3702.    10    229. pre0_mod04…\n 3    0.001                15 rmse    standard   3706.    10    227. pre0_mod08…\n 4    0.000000001          11 rmse    standard   3712.    10    222. pre0_mod02…\n 5    0.000001             13 rmse    standard   3712.    10    222. pre0_mod05…\n 6    0.0000000001          5 rmse    standard   3791.    10    228. pre0_mod01…\n 7    0.01                  4 rmse    standard   4346.    10    206. pre0_mod09…\n 8    0.00001               2 rmse    standard   4543.    10    197. pre0_mod06…\n 9    0.1                  10 rmse    standard   5382.    10    169. pre0_mod10…\n10    0.00000001            1 rmse    standard   6892.    10    255. pre0_mod03…\n\n\n\n# Get the best model's tuning parameter values\nbest_tree &lt;- select_best(tree_fit, metric = \"rmse\")\nbest_tree\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config         \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;           \n1          0.0001          8 pre0_mod07_post0\n\n\n\n# Finalize workflow and fit to entire training set\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(best_tree)\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(data_split, metrics = metric_set(rmse, mae))\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits           id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;           &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [263/90]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       3247. pre0_mod0_post0\n2 mae     standard       2500. pre0_mod0_post0\n\n\n\n\nBagged Tree model\n\n# Set up model and engine\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.5.2\n\nbag_mod &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n# Create workflow\nbag_wkf &lt;- workflow() |&gt;\n add_recipe(recipe_one) |&gt;\n add_model(bag_mod)\n\n# Fit to CV folds\nbag_fit &lt;- bag_wkf |&gt;\n  tune_grid(resamples = bike_folds,\n            grid = grid_regular(cost_complexity(),  #tuning parameter of interest\n                                levels = 15),    #it will choose 15 values\n            metrics = metric_set(rmse, mae))\n\nRegistered S3 method overwritten by 'butcher':\n  method                 from    \n  as.character.dev_topic generics\n\n\n→ A | warning: There was 1 warning in `dplyr::mutate()`.\n               ℹ In argument: `model = iter(...)`.\n               Caused by warning:\n               ! package 'future' was built under R version 4.5.2\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n# Check metrics\nbag_fit |&gt;\n  collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 30 × 7\n   cost_complexity .metric .estimator  mean     n std_err .config         \n             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1        3.16e- 6 mae     standard   2502.    10   141.  pre0_mod08_post0\n 2        2.68e- 4 mae     standard   2513.    10   140.  pre0_mod11_post0\n 3        3.73e- 8 mae     standard   2527.    10   122.  pre0_mod05_post0\n 4        4.39e-10 mae     standard   2540.    10   145.  pre0_mod02_post0\n 5        8.48e- 9 mae     standard   2557.    10   141.  pre0_mod04_post0\n 6        1.93e- 9 mae     standard   2567.    10    97.5 pre0_mod03_post0\n 7        1.64e- 7 mae     standard   2610.    10   156.  pre0_mod06_post0\n 8        6.11e- 5 mae     standard   2611.    10   157.  pre0_mod10_post0\n 9        1   e-10 mae     standard   2612.    10   129.  pre0_mod01_post0\n10        1.18e- 3 mae     standard   2625.    10   131.  pre0_mod12_post0\n# ℹ 20 more rows\n\n\n\n# Get best tuning parameter\nbag_best &lt;- select_best(bag_fit, metric = \"rmse\")\nbag_best\n\n# A tibble: 1 × 2\n  cost_complexity .config         \n            &lt;dbl&gt; &lt;chr&gt;           \n1    0.0000000373 pre0_mod05_post0\n\n\n\n# Refit on the entire training set using the tuning parameter\nbag_final_wkf &lt;- bag_wkf |&gt;\n  finalize_workflow(bag_best)\n\nbag_final_fit &lt;- bag_final_wkf |&gt;\n  last_fit(data_split, metrics = metric_set(rmse, mae))\n#last fit fits to training data and tests on test data\n\nbag_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       2953. pre0_mod0_post0\n2 mae     standard       2297. pre0_mod0_post0\n\n\n\n\nRandom Forest Model\n\n#Extract function\nget_rf_imp &lt;- function(x) {\n    x %&gt;% \n        extract_fit_parsnip() %&gt;% \n        vip::vi()\n}\n\n# Set up model and engine\nrf_mod &lt;- rand_forest(mtry = tune()) |&gt;\n set_engine(\"ranger\", importance = \"impurity\") |&gt;\n set_mode(\"regression\")\n\n# This is to get the variable importance \nctrl_imp &lt;- control_grid(extract = get_rf_imp)\n\n#create workflows\n rf_wkf &lt;- workflow() |&gt;\n   add_recipe(recipe_one) |&gt;\n   add_model(rf_mod)\n \n # Fit CV folds\n rf_fit &lt;- rf_wkf |&gt;\n  tune_grid(resamples = bike_folds,\n            grid = 7,  #7 total values\n            metrics = metric_set(rmse, mae),\n            control = ctrl_imp)    # variable importance\n\ni Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n\n # Check metrics across folds\n rf_fit |&gt;\n  collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 14 × 7\n    mtry .metric .estimator  mean     n std_err .config        \n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n 1    13 mae     standard   2292.    10    126. pre0_mod7_post0\n 2    11 mae     standard   2325.    10    131. pre0_mod6_post0\n 3     9 mae     standard   2340.    10    131. pre0_mod5_post0\n 4     7 mae     standard   2358.    10    130. pre0_mod4_post0\n 5     5 mae     standard   2429.    10    127. pre0_mod3_post0\n 6     3 mae     standard   2558.    10    115. pre0_mod2_post0\n 7    13 rmse    standard   2896.    10    149. pre0_mod7_post0\n 8    11 rmse    standard   2916.    10    150. pre0_mod6_post0\n 9     9 rmse    standard   2942.    10    148. pre0_mod5_post0\n10     7 rmse    standard   2966.    10    134. pre0_mod4_post0\n11     5 rmse    standard   3064.    10    127. pre0_mod3_post0\n12     3 rmse    standard   3195.    10    117. pre0_mod2_post0\n13     1 mae     standard   4163.    10    151. pre0_mod1_post0\n14     1 rmse    standard   4883.    10    156. pre0_mod1_post0\n\n\n\n# Get best tuning parameter\nrf_best &lt;- select_best(rf_fit, metric = \"rmse\")\nrf_best\n\n# A tibble: 1 × 2\n   mtry .config        \n  &lt;int&gt; &lt;chr&gt;          \n1    13 pre0_mod7_post0\n\n\n\n# Refit on entire training set using the tuning parameter.\nrf_final_wkf &lt;- rf_wkf |&gt;\n finalize_workflow(rf_best)\nrf_final_fit &lt;- rf_final_wkf |&gt;\n last_fit(data_split, metrics = metric_set(rmse, mae))\n\nrf_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       2761. pre0_mod0_post0\n2 mae     standard       2123. pre0_mod0_post0\n\n\n\n\nMLR Model\n\n# Fit MLR best model on the entire training data set, and get RMSE and MAE metrics\nMLR_final_fit &lt;- workflow_three |&gt;\n  last_fit(data_split, metrics = metric_set(rmse, mae))\n\n\n\nCompare models.\n\nrbind(\n  MLR_final_fit |&gt;\n    collect_metrics() |&gt; \n    mutate(Model = \"MLR\", .before = \".metric\"),\n  LASSO_final_fit |&gt;\n    collect_metrics() |&gt; \n    mutate(Model = \"LASSO\", .before = \".metric\"), \n  tree_final_fit |&gt;\n    collect_metrics() |&gt; \n    mutate(Model = \"TREE\", .before = \".metric\"), \n  bag_final_fit |&gt;\n    collect_metrics() |&gt; \n    mutate(Model = \"BAG\", .before = \".metric\"),\n  rf_final_fit |&gt;\n    collect_metrics() |&gt; \n    mutate(Model = \"RF\", .before = \".metric\")\n) |&gt;\n  arrange(.metric, .estimate)\n\n# A tibble: 10 × 5\n   Model .metric .estimator .estimate .config        \n   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n 1 RF    mae     standard       2123. pre0_mod0_post0\n 2 MLR   mae     standard       2220. pre0_mod0_post0\n 3 BAG   mae     standard       2297. pre0_mod0_post0\n 4 TREE  mae     standard       2500. pre0_mod0_post0\n 5 LASSO mae     standard       3157. pre0_mod0_post0\n 6 RF    rmse    standard       2761. pre0_mod0_post0\n 7 MLR   rmse    standard       2950. pre0_mod0_post0\n 8 BAG   rmse    standard       2953. pre0_mod0_post0\n 9 TREE  rmse    standard       3247. pre0_mod0_post0\n10 LASSO rmse    standard       4060. pre0_mod0_post0\n\n\nThe Random Forest Model is the best model.\n\n\nExtracting the final model fits for each type\nMLR Model, with final coefficient table:\n\nMLR_final_model &lt;- extract_workflow(MLR_final_fit) \nMLR_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n7 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n• step_interact()\n• step_poly()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n                             (Intercept)  \n                                   15127  \n                          seasons_Spring  \n                                   -7314  \n                          seasons_Summer  \n                                   17027  \n                          seasons_Winter  \n                                   -7739  \n                      holiday_No.Holiday  \n                                    6216  \n                     day_of_week_weekend  \n                                   -2433  \n     holiday_No.Holiday_x_seasons_Spring  \n                                    2520  \n     holiday_No.Holiday_x_seasons_Summer  \n                                   -2849  \n     holiday_No.Holiday_x_seasons_Winter  \n                                   -3753  \n     seasons_Spring_x_mean_temperature_c  \n                                    4524  \n     seasons_Summer_x_mean_temperature_c  \n                                  -15421  \n     seasons_Winter_x_mean_temperature_c  \n                                   -6039  \n               mean_temperature_c_poly_1  \n                                    2631  \n               mean_temperature_c_poly_2  \n                                  -20202  \n            mean_humidity_percent_poly_1  \n                                  -41810  \n            mean_humidity_percent_poly_2  \n                                    1707  \n              mean_wind_speed_m_s_poly_1  \n                                   -7189  \n              mean_wind_speed_m_s_poly_2  \n                                    2555  \n              mean_visibility_10m_poly_1  \n                                    2599  \n              mean_visibility_10m_poly_2  \n                                   -3261  \n     mean_dew_point_temperature_c_poly_1  \n                                  114130  \n     mean_dew_point_temperature_c_poly_2  \n                                   -6282  \n       mean_solar_radiation_mj_m2_poly_1  \n\n...\nand 16 more lines.\n\ntidy(MLR_final_model)\n\n# A tibble: 30 × 5\n   term                                estimate std.error statistic  p.value\n   &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                           15127.     2181.     6.93  3.97e-11\n 2 seasons_Spring                        -7314.     3715.    -1.97  5.02e- 2\n 3 seasons_Summer                        17027.     3515.     4.84  2.33e- 6\n 4 seasons_Winter                        -7739.     3180.    -2.43  1.57e- 2\n 5 holiday_No.Holiday                     6216.     2055.     3.03  2.77e- 3\n 6 day_of_week_weekend                   -2433.      392.    -6.21  2.47e- 9\n 7 holiday_No.Holiday_x_seasons_Spring    2520.     3752.     0.672 5.02e- 1\n 8 holiday_No.Holiday_x_seasons_Summer   -2849.     2881.    -0.989 3.24e- 1\n 9 holiday_No.Holiday_x_seasons_Winter   -3753.     2459.    -1.53  1.28e- 1\n10 seasons_Spring_x_mean_temperature_c    4524.     1115.     4.06  6.80e- 5\n# ℹ 20 more rows\n\n\nLASSO Model, with final coefficient table:\n\nLASSO_final_model &lt;- extract_fit_parsnip(LASSO_final_fit) \nLASSO_final_model\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00 7309.0\n2   2 11.30 6660.0\n3   2 21.30 6068.0\n4   2 29.61 5529.0\n5   3 36.87 5038.0\n6   3 43.03 4590.0\n7   3 48.15 4182.0\n8   3 52.40 3811.0\n9   3 55.93 3472.0\n10  3 58.85 3164.0\n11  3 61.29 2883.0\n12  3 63.31 2627.0\n13  3 64.98 2393.0\n14  3 66.37 2181.0\n15  4 67.58 1987.0\n16  4 69.32 1810.0\n17  4 70.77 1650.0\n18  4 71.97 1503.0\n19  4 72.97 1370.0\n20  4 73.79 1248.0\n21  4 74.48 1137.0\n22  5 75.25 1036.0\n23  6 76.26  944.0\n24  6 77.13  860.1\n25  7 77.91  783.7\n26  7 78.57  714.1\n27  7 79.12  650.7\n28  7 79.58  592.9\n29  8 79.97  540.2\n30  8 80.33  492.2\n31  8 80.63  448.5\n32  9 80.88  408.6\n33 10 81.11  372.3\n34 10 81.56  339.3\n35 10 81.93  309.1\n36 10 82.24  281.7\n37 10 82.50  256.6\n38 10 82.71  233.8\n39 10 82.89  213.1\n40 10 83.04  194.1\n41 10 83.16  176.9\n42 10 83.26  161.2\n43 11 83.34  146.9\n44 11 83.42  133.8\n45 11 83.48  121.9\n46 11 83.52  111.1\n47 11 83.57  101.2\n48 11 83.60   92.2\n49 11 83.63   84.0\n50 11 83.65   76.6\n51 11 83.67   69.8\n52 11 83.69   63.6\n53 11 83.70   57.9\n54 11 83.71   52.8\n55 11 83.72   48.1\n56 11 83.73   43.8\n57 11 83.74   39.9\n58 11 83.74   36.4\n59 11 83.75   33.1\n60 11 83.75   30.2\n61 12 83.75   27.5\n62 13 83.76   25.1\n63 13 83.76   22.9\n64 13 83.76   20.8\n65 13 83.77   19.0\n66 13 83.77   17.3\n67 13 83.78   15.8\n68 13 83.79   14.3\n69 13 83.80   13.1\n70 13 83.80   11.9\n71 13 83.80   10.8\n72 13 83.81    9.9\n73 13 83.81    9.0\n74 13 83.81    8.2\n75 13 83.82    7.5\n76 13 83.82    6.8\n77 13 83.82    6.2\n78 13 83.82    5.7\n79 13 83.82    5.2\n80 13 83.82    4.7\n81 13 83.83    4.3\n82 13 83.83    3.9\n83 13 83.83    3.6\n\ntidy(LASSO_final_model)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-10\n\n\n# A tibble: 14 × 3\n   term                         estimate      penalty\n   &lt;chr&gt;                           &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)                    19600. 0.0000000001\n 2 sum_rainfall                   -1778. 0.0000000001\n 3 sum_snowfall                    -289. 0.0000000001\n 4 mean_temperature_c              1426. 0.0000000001\n 5 mean_humidity_percent          -1221. 0.0000000001\n 6 mean_wind_speed_m_s             -560. 0.0000000001\n 7 mean_visibility_10m             -132. 0.0000000001\n 8 mean_dew_point_temperature_c    3212. 0.0000000001\n 9 mean_solar_radiation_mj_m2      3894. 0.0000000001\n10 seasons_Spring                 -5599. 0.0000000001\n11 seasons_Summer                 -4898. 0.0000000001\n12 seasons_Winter                 -8277. 0.0000000001\n13 holiday_No.Holiday              3325. 0.0000000001\n14 day_of_week_weekend            -2367. 0.0000000001\n\n\nRegression Tree Model:\n\ntree_final_model &lt;- extract_workflow(tree_final_fit) \ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 263 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n  1) root 263 25536330000 17295.190  \n    2) mean_temperature_c&lt; -0.2623656 109  2929334000  8638.789  \n      4) seasons_Winter&gt;=0.5 67   238111900  5474.194  \n        8) mean_temperature_c&lt; -1.537823 21    24940570  4077.095  \n         16) mean_temperature_c&lt; -1.848146 8     3295468  3517.500 *\n         17) mean_temperature_c&gt;=-1.848146 13    17598290  4421.462 *\n        9) mean_temperature_c&gt;=-1.537823 46   153469100  6112.000  \n         18) sum_snowfall&gt;=1.085861 8    10038760  4350.250 *\n         19) sum_snowfall&lt; 1.085861 38   113372800  6482.895  \n           38) day_of_week_weekend&gt;=0.5 10    30304920  5604.200 *\n           39) day_of_week_weekend&lt; 0.5 28    72589330  6796.714  \n             78) mean_visibility_10m&gt;=0.8931158 8    25601820  5628.875 *\n             79) mean_visibility_10m&lt; 0.8931158 20    31712400  7263.850  \n              158) mean_solar_radiation_mj_m2&lt; -1.03862 9    10843330  6650.222 *\n              159) mean_solar_radiation_mj_m2&gt;=-1.03862 11    14707520  7765.909 *\n      5) seasons_Winter&lt; 0.5 42   949863600 13687.070  \n       10) sum_rainfall&gt;=-0.2571349 11   139349100  8418.273 *\n       11) sum_rainfall&lt; -0.2571349 31   396797400 15556.650  \n         22) seasons_Spring&gt;=0.5 14    76964920 13076.500 *\n         23) seasons_Spring&lt; 0.5 17   162798000 17599.120 *\n    3) mean_temperature_c&gt;=-0.2623656 154  8658212000 23422.120  \n      6) mean_solar_radiation_mj_m2&lt; -1.012344 18   336145000  8131.056 *\n      7) mean_solar_radiation_mj_m2&gt;=-1.012344 136  3556331000 25445.940  \n       14) sum_rainfall&gt;=-0.1574262 21   389911600 20657.710  \n         28) day_of_week_weekend&gt;=0.5 8   105784700 18339.250 *\n         29) day_of_week_weekend&lt; 0.5 13   214661800 22084.460 *\n       15) sum_rainfall&lt; -0.1574262 115  2597029000 26320.310  \n         30) mean_temperature_c&lt; 0.3549168 34   574640800 23217.940  \n           60) mean_visibility_10m&lt; -0.3624895 12   229010000 19939.330 *\n           61) mean_visibility_10m&gt;=-0.3624895 22   146280700 25006.270  \n            122) mean_visibility_10m&lt; 0.7457674 10    52168030 23576.900 *\n            123) mean_visibility_10m&gt;=0.7457674 12    56655700 26197.420 *\n         31) mean_temperature_c&gt;=0.3549168 81  1557788000 27622.540  \n           62) mean_temperature_c&gt;=1.500792 14    72606990 21297.930 *\n           63) mean_temperature_c&lt; 1.500792 67   808153800 28944.100  \n            126) mean_temperature_c&lt; 0.5813303 12   150799500 25954.330 *\n            127) mean_temperature_c&gt;=0.5813303 55   526686300 29596.420  \n              254) mean_dew_point_temperature_c&gt;=0.9189753 21    96862780 27196.810  \n                508) mean_temperature_c&gt;=1.25526 11    27591330 26032.640 *\n                509) mean_temperature_c&lt; 1.25526 10    37964040 28477.400 *\n              255) mean_dew_point_temperature_c&lt; 0.9189753 34   234216800 31078.530  \n                510) seasons_Summer&lt; 0.5 16    51196240 29933.380 *\n                511) seasons_Summer&gt;=0.5 18   143387700 32096.440 *\n\n\nPlot of final fit for the regression tree model:\n\ntree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\nBagged tree model, with a variable importance plot:\n\nbag_final_model &lt;- extract_fit_engine(bag_final_fit)\n\nbag_final_model$imp |&gt;\n  mutate(term = factor(term, levels = term)) |&gt;\n  ggplot(aes(x = term, y = value)) +\n  geom_bar(stat =\"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nTemperature was the most important to # of bike rentals.\nRandom Forest Model variable importance plot:\n\nrf_fit %&gt;%\n    select(id, .extracts) %&gt;%\n    unnest(.extracts) %&gt;%\n    unnest(.extracts) %&gt;%\n    group_by(Variable) %&gt;%\n    summarise(Mean = mean(Importance),\n              Variance = sd(Importance)) %&gt;%\n    slice_max(Mean, n = 15) %&gt;%\n    ggplot(aes(Mean, reorder(Variable, Mean))) +\n    geom_crossbar(aes(xmin = Mean - Variance, xmax = Mean + Variance)) +\n    labs(x = \"Variable importance\", y = NULL)\n\n\n\n\n\n\n\n\nFit the best model to the entire data set!"
  }
]